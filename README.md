# ğŸ¯ Whisper Pronunciation Tuning

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.5.0+-ee4c2c.svg)
![Transformers](https://img.shields.io/badge/ğŸ¤—%20Transformers-4.35.0+-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

Un sistema completo de fine-tuning de Whisper para anÃ¡lisis de pronunciaciÃ³n en inglÃ©s usando el dataset speechocean762. Este proyecto entrena un modelo de IA generativa que puede detectar y ayudar a corregir errores de pronunciaciÃ³n en inglÃ©s, proporcionando anÃ¡lisis detallado con puntuaciones especÃ­ficas y recomendaciones personalizadas.

## ğŸŒŸ CaracterÃ­sticas Principales

- **ğŸ”¥ Fine-tuning eficiente** de Whisper usando LoRA (Low-Rank Adaptation)
- **ğŸ“Š AnÃ¡lisis multi-nivel**: sentence-level, word-level, y phoneme-level
- **ğŸ¯ DetecciÃ³n de errores especÃ­ficos** de pronunciaciÃ³n con localizaciones precisas
- **ğŸ’¡ Recomendaciones personalizadas** para mejora de pronunciaciÃ³n
- **âš¡ Interfaz de lÃ­nea de comandos** fÃ¡cil de usar
- **ğŸ“ˆ Visualizaciones interactivas** de resultados
- **ğŸ”„ Procesamiento en lote** de mÃºltiples archivos de audio
- **ğŸš€ OptimizaciÃ³n de memoria** con Accelerate y LoRA
- **ğŸ“± Demo interactivo** con interface web

## ğŸ“Š Dataset: speechocean762

Este proyecto utiliza [speechocean762](https://huggingface.co/datasets/mispeech/speechocean762), un dataset open-source diseÃ±ado especÃ­ficamente para evaluaciÃ³n de pronunciaciÃ³n:

| CaracterÃ­stica | Detalle |
|---|---|
| **Utterances** | 5,000 grabaciones en inglÃ©s |
| **Hablantes** | 250 hablantes no nativos |
| **Niveles de anÃ¡lisis** | Sentence, Word, Phoneme |
| **MÃ©tricas** | Accuracy, Fluency, Completeness, Prosody |
| **Anotaciones** | Expertas con informaciÃ³n de mispronunciaciones |

## ğŸš€ InstalaciÃ³n

### Requisitos del Sistema

- **Python** 3.11+
- **CUDA-compatible GPU** (recomendado para entrenamiento)
- **RAM** 16GB+ (32GB+ recomendado para modelos grandes)
- **Espacio en disco** 10GB+ para modelos y cache

### InstalaciÃ³n con uv (Recomendado)

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/whisper-pronunciation-tuning.git
cd whisper-pronunciation-tuning

# Instalar dependencias con uv
uv sync

# Activar el entorno virtual
source .venv/bin/activate  # Linux/Mac
# o
.venv\Scripts\activate     # Windows
```

### InstalaciÃ³n Alternativa con pip

```bash
# Instalar en modo desarrollo
pip install -e .

# O desde requirements
pip install -r requirements.txt
```

### Verificar InstalaciÃ³n

```bash
# Verificar CUDA
python check_cuda.py

# Probar el sistema
python main.py test-data
```

## ğŸ“– GuÃ­a de Uso

### 1. ğŸ‹ï¸ Entrenamiento del Modelo

#### Entrenamiento BÃ¡sico (Recomendado)

```bash
# ConfiguraciÃ³n inicial para principiantes
uv run python main.py train --epochs 5 --batch-size 2
```

#### Entrenamiento Avanzado

```bash
# ConfiguraciÃ³n completa con parÃ¡metros optimizados
uv run python main.py train \
    --model-name openai/whisper-base \
    --epochs 10 \
    --batch-size 4 \
    --learning-rate 1e-4 \
    --lora-r 32 \
    --lora-alpha 64 \
    --gradient-accumulation-steps 8
```

#### ParÃ¡metros de Entrenamiento

| ParÃ¡metro | DescripciÃ³n | Valores Recomendados |
|---|---|---|
| `--model-name` | Modelo base de Whisper | `whisper-small`, `whisper-base`, `whisper-large` |
| `--epochs` | NÃºmero de Ã©pocas | 5-15 |
| `--batch-size` | TamaÃ±o de lote | 2-8 (segÃºn GPU) |
| `--learning-rate` | Tasa de aprendizaje | 5e-5 a 2e-4 |
| `--lora-r` | Rank de LoRA | 16-64 |
| `--lora-alpha` | Alpha de LoRA | 32-128 |
| `--gradient-accumulation-steps` | AcumulaciÃ³n de gradiente | 4-16 |

### 2. ğŸµ AnÃ¡lisis de PronunciaciÃ³n

#### Archivo Individual

```bash
# AnÃ¡lisis bÃ¡sico
uv run python main.py analyze --audio-file mi_audio.wav

# Con directorio de salida personalizado
uv run python main.py analyze \
    --audio-file mi_audio.wav \
    --output-dir ./mis_resultados
```

#### Procesamiento en Lote

```bash
# Analizar directorio completo
uv run python main.py analyze \
    --audio-dir ./audios \
    --output-dir ./resultados
```

#### Formatos de Audio Soportados

- **WAV** (recomendado)
- **MP3**
- **FLAC**
- **OGG**
- **M4A**

### 3. ğŸ§ª Demos y Pruebas

```bash
# DemostraciÃ³n interactiva
uv run python demo_inference.py

# Demo sin visualizaciones
uv run python demo_inference.py --no-visualizations

# Probar cargador de datos
uv run python main.py test-data

# InformaciÃ³n del modelo
uv run python main.py info
```

## ğŸ“‹ Ejemplo de Salida

### AnÃ¡lisis Completo

```
============================================================
ğŸ¯ REPORTE DE ANÃLISIS DE PRONUNCIACIÃ“N
============================================================

ğŸ“ TRANSCRIPCIÃ“N: "The quick brown fox jumps over the lazy dog"

ğŸ“Š PUNTUACIONES GENERALES:
   â€¢ ğŸ¯ PrecisiÃ³n General: 7.5/10
   â€¢ ğŸ“ˆ PrecisiÃ³n: 8.0/10
   â€¢ ğŸŒŠ Fluidez: 7.0/10
   â€¢ âœ… Completitud: 0.9/1.0
   â€¢ ğŸµ Prosodia: 7.5/10

âš ï¸  ERRORES A NIVEL DE PALABRAS:
   â€¢ "quick" â†’ 6.2/10
     â””â”€ Dificultad con el sonido 'qu' inicial
   â€¢ "jumps" â†’ 7.1/10
     â””â”€ PronunciaciÃ³n de la 's' final unclear

ğŸ”Š ERRORES DE FONEMAS:
   â€¢ Palabra "quick": /k/ â†’ /g/ (oclusiva sorda â†’ sonora)
   â€¢ Palabra "jumps": /s/ â†’ <unk> (sonido final no reconocido)

ğŸ’¡ RECOMENDACIONES PERSONALIZADAS:
   1. ğŸ¯ Practica las oclusivas sordas (/k/, /p/, /t/)
   2. ğŸŒŠ Trabaja en la fluidez evitando pausas largas
   3. ğŸ”š EnfÃ³cate en las consonantes finales
   4. ğŸµ Mejora la entonaciÃ³n natural del inglÃ©s

ğŸ¯ Confianza del anÃ¡lisis: 85.3%
â±ï¸  Tiempo de procesamiento: 2.3s
============================================================
```

## ğŸ—ï¸ Arquitectura del Proyecto

### Estructura de Directorios

```
whisper-pronunciation-tuning/
â”œâ”€â”€ ğŸ“ cache/                    # Cache de datasets y modelos
â”œâ”€â”€ ğŸ“ logs/                     # Logs de entrenamiento
â”œâ”€â”€ ğŸ“ analysis_results/         # Resultados de anÃ¡lisis
â”œâ”€â”€ ğŸ“ whisper-pronunciation-tuned/ # Modelos entrenados
â”œâ”€â”€ ğŸ“„ main.py                   # Interfaz principal CLI
â”œâ”€â”€ ğŸ“„ data_loader.py           # Cargador de speechocean762
â”œâ”€â”€ ğŸ“„ whisper_pronunciation_trainer.py # Entrenador con LoRA
â”œâ”€â”€ ğŸ“„ pronunciation_analyzer.py # Analizador de pronunciaciÃ³n
â”œâ”€â”€ ğŸ“„ demo_inference.py        # Demo interactivo
â”œâ”€â”€ ğŸ“„ check_cuda.py            # Verificador de CUDA
â””â”€â”€ ğŸ“„ pyproject.toml           # ConfiguraciÃ³n del proyecto
```

### Componentes Principales

| Componente | FunciÃ³n |
|---|---|
| **data_loader.py** | Carga y preprocesamiento del dataset speechocean762 |
| **whisper_pronunciation_trainer.py** | Fine-tuning de Whisper con LoRA |
| **pronunciation_analyzer.py** | AnÃ¡lisis de pronunciaciÃ³n en tiempo real |
| **main.py** | Interfaz principal de lÃ­nea de comandos |
| **demo_inference.py** | DemostraciÃ³n interactiva con visualizaciones |

### Flujo de Trabajo

```mermaid
graph TD
    A[Dataset speechocean762] --> B[Preprocesamiento]
    B --> C[Fine-tuning con LoRA]
    C --> D[Modelo Entrenado]
    D --> E[AnÃ¡lisis de Audio]
    E --> F[Reporte Detallado]
    F --> G[Recomendaciones]
```

## âš™ï¸ ConfiguraciÃ³n Avanzada

### OptimizaciÃ³n para Diferentes GPUs

#### GPU con 8GB+ (RTX 3070, RTX 4060 Ti)

```bash
uv run python main.py train \
    --model-name openai/whisper-small \
    --batch-size 4 \
    --gradient-accumulation-steps 4 \
    --lora-r 32 \
    --fp16
```

#### GPU con 16GB+ (RTX 4080, RTX 4090)

```bash
uv run python main.py train \
    --model-name openai/whisper-base \
    --batch-size 8 \
    --gradient-accumulation-steps 2 \
    --lora-r 64 \
    --fp16
```

#### GPU con 24GB+ (RTX 6000, A6000)

```bash
uv run python main.py train \
    --model-name openai/whisper-large \
    --batch-size 16 \
    --gradient-accumulation-steps 1 \
    --lora-r 128 \
    --fp16
```

### ConfiguraciÃ³n LoRA por Modelo

```python
# Configuraciones recomendadas
WHISPER_SMALL = {
    "lora_r": 32,
    "lora_alpha": 64,
    "lora_dropout": 0.1,
    "batch_size": 4
}

WHISPER_BASE = {
    "lora_r": 64,
    "lora_alpha": 128,
    "lora_dropout": 0.1,
    "batch_size": 6
}

WHISPER_LARGE = {
    "lora_r": 128,
    "lora_alpha": 256,
    "lora_dropout": 0.05,
    "batch_size": 8
}
```

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

### MÃ©tricas Principales

| MÃ©trica | DescripciÃ³n | Rango |
|---|---|---|
| **WER** | Word Error Rate - Tasa de errores de palabras | 0.0-1.0 (menor es mejor) |
| **BLEU** | Calidad de generaciÃ³n de texto | 0.0-1.0 (mayor es mejor) |
| **Accuracy** | PrecisiÃ³n de pronunciaciÃ³n | 0-10 |
| **Fluency** | Fluidez del habla | 0-10 |
| **Completeness** | Completitud de pronunciaciÃ³n | 0-1 |
| **Prosody** | Calidad prosÃ³dica | 0-10 |

### InterpretaciÃ³n de Resultados

- **8.0-10.0**: PronunciaciÃ³n excelente
- **6.0-7.9**: PronunciaciÃ³n buena con Ã¡reas de mejora
- **4.0-5.9**: PronunciaciÃ³n promedio, necesita prÃ¡ctica
- **0.0-3.9**: PronunciaciÃ³n necesita trabajo significativo

## ğŸ¨ Visualizaciones

El sistema incluye visualizaciones automÃ¡ticas:

- **ğŸ“Š GrÃ¡ficos de barras** de puntuaciones por categorÃ­a
- **ğŸ”¥ Mapas de calor** de mÃ©tricas mÃºltiples
- **ğŸ“‹ AnÃ¡lisis de errores** por palabra y fonema
- **ğŸ“ˆ Tendencias de mejora** a lo largo del entrenamiento
- **ğŸ¯ Matrices de confusiÃ³n** para clasificaciÃ³n de fonemas

## ğŸ”§ Troubleshooting

### Problemas Comunes

#### 1. Error de Memoria GPU

```bash
# SÃ­ntoma: "CUDA out of memory"
# SoluciÃ³n: Reducir batch size
uv run python main.py train --batch-size 1 --gradient-accumulation-steps 16

# O usar CPU (muy lento)
CUDA_VISIBLE_DEVICES="" uv run python main.py train --epochs 1
```

#### 2. Dataset No Encontrado

```bash
# SÃ­ntoma: "Dataset not found"
# SoluciÃ³n: El dataset se descarga automÃ¡ticamente
# AsegÃºrate de tener:
# - ConexiÃ³n a internet
# - Espacio en disco (5GB+)
# - Permisos de escritura en ./cache
```

#### 3. Modelo No Encontrado para AnÃ¡lisis

```bash
# SÃ­ntoma: "Model not found"
# SoluciÃ³n: Entrena el modelo primero
uv run python main.py train --epochs 5 --batch-size 2

# Verifica que existe el directorio
ls -la ./whisper-pronunciation-tuned/
```

#### 4. Problemas de Transformers

```bash
# SÃ­ntoma: "evaluation_strategy not found"
# SoluciÃ³n: Actualizar transformers
pip install --upgrade transformers>=4.35.0

# O usar uv
uv add transformers@latest
```

#### 5. Problemas con CUDA

```bash
# Verificar instalaciÃ³n CUDA
python check_cuda.py

# Reinstalar PyTorch con CUDA
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Logs y Debugging

```bash
# Habilitar logging detallado
export PYTHONPATH=.
export CUDA_LAUNCH_BLOCKING=1
uv run python main.py train --epochs 1 --batch-size 1 --verbose

# Verificar uso de memoria
watch -n 1 nvidia-smi
```

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Por favor:

1. **Fork** el repositorio
2. **Crear** una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. **Commit** tus cambios (`git commit -am 'Agrega nueva funcionalidad'`)
4. **Push** a la rama (`git push origin feature/nueva-funcionalidad`)
5. **Crear** un Pull Request

### Desarrollo

```bash
# Instalar dependencias de desarrollo
uv add --dev pytest black isort flake8

# Ejecutar tests
uv run pytest

# Formatear cÃ³digo
uv run black .
uv run isort .

# Linting
uv run flake8 .
```

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- **OpenAI** por el modelo Whisper
- **Hugging Face** por transformers y datasets
- **speechocean762** por el dataset de pronunciaciÃ³n
- **Microsoft** por el framework LoRA (PEFT)

## ğŸ“ Soporte

Si tienes problemas:

1. Revisa la secciÃ³n **Troubleshooting**
2. Busca en los **Issues** existentes
3. Crea un **nuevo Issue** con:
   - DescripciÃ³n del problema
   - Logs de error
   - InformaciÃ³n del sistema
   - Pasos para reproducir

---

**Â¡Hecho con â¤ï¸ para la comunidad de aprendizaje de idiomas!**
